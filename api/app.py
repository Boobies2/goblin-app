import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' 

from flask import send_from_directory
from flask import Flask, render_template, request, jsonify
from PIL import Image
import numpy as np
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
from keras.models import load_model
import io
import logging
from flask_cors import CORS
import requests
from sklearn.preprocessing import LabelEncoder
from concurrent.futures import ThreadPoolExecutor  
import logging
from logging.handlers import TimedRotatingFileHandler
import os
from datetime import datetime

def setup_logging():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    file_handler = TimedRotatingFileHandler(
        filename=os.path.join(log_dir, 'goblin_app.log'),
        when='midnight',  
        interval=1,       
        backupCount=7,    
        encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

setup_logging()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = Flask(__name__,
            static_folder=os.path.join('..', 'front', 'static'),
            template_folder=os.path.join('..', 'front'))

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è CORS
CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:*", "http://127.0.0.1:*"],
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}
OPENROUTER_API_KEY = "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"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –∫–ª—é—á
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
OPENROUTER_MODEL = "mistralai/devstral-small:free"  # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–µ–π
models = {
    'goblin': None,
    'chat': None,
    'personality': None
}
tokenizers = {
    'chat': None
}
label_encoder = None
executor = ThreadPoolExecutor(max_workers=4)  # –¢–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ

# –ú–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ª–∏—á–Ω–æ—Å—Ç–∏
class PersonalityClassifier(nn.Module):
    def __init__(self, input_size=7, num_classes=2):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, num_classes)
    
    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

def allowed_file(filename):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def load_models():
    global models, tokenizers, label_encoder
    
    try:
        # 1. –ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –≥–æ–±–ª–∏–Ω–∞ (Keras)
        logger.debug("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ goblin_detector2.h5...")
        models['goblin'] = load_model(os.path.join("models", "goblin_detector.h5"))
        
        # 2. –ú–æ–¥–µ–ª—å —á–∞—Ç-–±–æ—Ç–∞ (HuggingFace)
        logger.debug("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —á–∞—Ç–∞...")
        tokenizers['chat'] = AutoTokenizer.from_pretrained(os.path.join("models", "model_chat"))
        models['chat'] = AutoModelForCausalLM.from_pretrained(os.path.join("models", "model_chat"))
        
        # 3. –ú–æ–¥–µ–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ (PyTorch)
        logger.debug("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ç–µ—Å—Ç–∞ –ª–∏—á–Ω–æ—Å—Ç–∏...")
        models['personality'] = PersonalityClassifier()
        models['personality'].load_state_dict(torch.load(os.path.join("models", "personality_model.pth")))
        models['personality'].eval()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LabelEncoder
        label_encoder = LabelEncoder()
        label_encoder.fit(['Extrovert', 'Introvert'])
        
        logger.info("–í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    
    except Exception as e:  # <- –≠—Ç–æ—Ç –±–ª–æ–∫ –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω!
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {str(e)}")
        raise

def preprocess_image(image_file):
    """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏"""
    try:
        logger.debug("[1/5] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
        if not image_file:
            raise ValueError("–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—É—Å—Ç–æ–π")
        
        # –ü–µ—Ä–µ–º–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –Ω–∞ –Ω–∞—á–∞–ª–æ (–µ—Å–ª–∏ –æ–Ω —É–∂–µ —á–∏—Ç–∞–ª—Å—è)
        if hasattr(image_file, 'seek'):
            image_file.seek(0)
        
        logger.debug("[2/5] –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞...")
        img_bytes = image_file.read()
        
        if not img_bytes:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞")
        
        logger.debug("[3/5] –û—Ç–∫—Ä—ã—Ç–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        img = Image.open(io.BytesIO(img_bytes))
        
        logger.debug(f"[4/5] –§–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img.format}, —Ä–µ–∂–∏–º: {img.mode}, —Ä–∞–∑–º–µ—Ä: {img.size}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB (–µ—Å–ª–∏ PNG —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º –∏–ª–∏ grayscale)
        if img.mode != 'RGB':
            logger.debug("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB...")
            img = img.convert('RGB')
        
        logger.debug("[5/5] –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è...")
        img = img.resize((128, 128))  # –†–∞–∑–º–µ—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –≤—Ö–æ–¥–æ–º –º–æ–¥–µ–ª–∏
        img_array = np.array(img) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0, 1]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º—ã –º–∞—Å—Å–∏–≤–∞
        if img_array.shape != (128, 128, 3):
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è —Ñ–æ—Ä–º–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_array.shape}. –û–∂–∏–¥–∞–µ—Ç—Å—è (128, 128, 3)")
        
        return np.expand_dims(img_array, axis=0)  # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞: (1, 128, 128, 3)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}", exc_info=True)
        raise

def interpret_goblin(prob):
    """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–±–ª–∏–Ω–∞"""
    if prob > 0.8:
        return "–î–∞ —Ç—ã.. –î–∞ —Ç—ã.. –¥–∞ —Ç—ã.. –ì–æ–±–ª–∏–Ω!! üèÜ"
    elif prob > 0.6:
        return "–Ω—É –ø–æ—Ö–æ–∂ —á—É—á—É—Ç—å"
    elif prob > 0.4:
        return "–ù–æ—Å –≥–æ–±–ª–∏–Ω—Å–∫–∏–π —á—Ç–æ–ª—å"
    elif prob > 0.2:
        return "–ï—Å–ª–∏ –≥–ª–∞–∑–∞ –∑–∞–∫—Ä—ã—Ç—å —Ç–æ —á—É—á—É—Ç—å –ø–æ—Ö–æ–∂"
    else:
        return "–¢–´ –ù–ï –ì–û–ë–õ–ò–ù"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
load_models()

# ===== –†–æ—É—Ç—ã =====
@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html')

@app.route('/tresure')
def tresure():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–∫—Ä–æ–≤–∏—â–Ω–∏—Ü—ã"""
    return render_template('tresure.html')

@app.route('/favicon.ico')
def favicon():
    return send_from_directory(os.path.join(app.root_path, 'static'),
                               'favicon.ico', mimetype='image/vnd.microsoft.icon')

@app.route('/api/detect_goblin', methods=['POST'])
def api_detect_goblin():
    try:
        if 'file' not in request.files:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"}), 400
            
        file = request.files['file']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ñ–∞–π–ª –µ—Å—Ç—å –∏ –∏–º–µ–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∏–º—è
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω"}), 400
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        if not allowed_file(file.filename):
            return jsonify({"error": "–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ PNG, JPG, JPEG"}), 400
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ
        logger.info(f"–ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {file.filename}, —Ä–∞–∑–º–µ—Ä: {file.content_length} bytes")
        
        # –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        debug_path = "debug_upload.jpg"
        file.save(debug_path)
        logger.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: {debug_path}")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img = preprocess_image(file)
        probability = float(models['goblin'].predict(img, verbose=0)[0][0])
        
        return jsonify({
            "probability": probability,
            "verdict": interpret_goblin(probability)
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ detect_goblin: {str(e)}", exc_info=True)
        return jsonify({"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"}), 500

@app.route('/api/personality_test', methods=['POST'])
def personality_test():
    try:
        # –î–æ–±–∞–≤–∏–º –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        app.logger.info("–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ç–µ—Å—Ç –ª–∏—á–Ω–æ—Å—Ç–∏")
        
        if not models.get('personality'):
            app.logger.error("–ú–æ–¥–µ–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            return jsonify({"error": "–ú–æ–¥–µ–ª—å –ª–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}), 503
            
        answers = request.json.get('answers', [])
        app.logger.info(f"–ü–æ–ª—É—á–µ–Ω—ã –æ—Ç–≤–µ—Ç—ã: {answers}")
        
        if len(answers) != 7:
            return jsonify({"error": "–¢—Ä–µ–±—É–µ—Ç—Å—è 7 –æ—Ç–≤–µ—Ç–æ–≤"}), 400
            
        input_tensor = torch.tensor([answers], dtype=torch.float32)
        
        with torch.no_grad():
            outputs = models['personality'](input_tensor)
            probs = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probs, 1)
            personality = label_encoder.inverse_transform(predicted.numpy())[0]
        
        interpretation = "–≠–∫—Å—Ç—Ä–∞–≤–µ—Ä—Ç" if personality == "Extrovert" else "–ò–Ω—Ç—Ä–æ–≤–µ—Ä—Ç"
        app.logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {personality} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence.item()})")
        
        return jsonify({
            "personality": personality,
            "confidence": confidence.item(),
            "interpretation": interpretation
        })
        
    except Exception as e:
        app.logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ –ª–∏—á–Ω–æ—Å—Ç–∏: {str(e)}", exc_info=True)
        return jsonify({"error": str(e)}), 500

@app.route('/api/chat', methods=['POST'])
def api_chat():
    try:
        data = request.get_json()
        user_input = data.get('text', '').strip().lower()
        use_local = data.get('model', '').lower() == 'local'

        if not user_input:
            return jsonify({"error": "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç"}), 400

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        restricted_words = ['–ø–∏—Å—å', '–ø–∏—Å–∞', '–ø–∏—Å—è', '—Ö—É–π', '–ø–∏–∑–¥']
        if any(word in user_input for word in restricted_words):
            return jsonify({
                "user_message": user_input,
                "response": "–ì–æ–±–ª–∏–Ω—ã –Ω–µ –æ–±—Å—É–∂–¥–∞—é—Ç —Ç–∞–∫–∏–µ –≤–µ—â–∏! *—Å–µ—Ä–¥–∏—Ç–æ –Ω–∞–¥—É–≤–∞–µ—Ç —â—ë–∫–∏*",
                "model": "filter"
            })

        if use_local:
            # –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
            inputs = tokenizers['chat'](user_input, return_tensors='pt')
            outputs = models['chat'].generate(
                **inputs,
                max_new_tokens=50,
                do_sample=True,
                temperature=0.7,
                no_repeat_ngram_size=2
            )
            full_response = tokenizers['chat'].decode(outputs[0], skip_special_tokens=True)
            response = full_response.split('\n')[0]
            
            logger.info(f"Local model response: {response}")
            
            return jsonify({
                "user_message": user_input,
                "response": response,
                "model": "local"
            })
        else:
            headers = {
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:5000",
                "X-Title": "Goblin Chat"
            }
            
            payload = {
                "model": OPENROUTER_MODEL,
                "messages": [
                    {
                        "role": "system", 
                        "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –≥–æ–±–ª–∏–Ω-—Ñ–∏–ª—å—Ç—Ä. –û—Ç–≤–µ—á–∞–π –≤–µ–∂–ª–∏–≤–æ –∏ –∫—É–ª—å—Ç—É—Ä–Ω–æ. –ò–∑–±–µ–≥–∞–π –Ω–µ–ø—Ä–∏–µ–º–ª–µ–º—ã—Ö —Ç–µ–º."
                    },
                    {"role": "user", "content": user_input}
                ],
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            response = requests.post(OPENROUTER_API_URL, headers=headers, json=payload)
            response_data = response.json()
            
            bot_response = response_data['choices'][0]['message']['content']
            
            return jsonify({
                "user_message": user_input,
                "response": bot_response,
                "model": OPENROUTER_MODEL
            })

    except Exception as e:
        logger.error(f"Chat error: {str(e)}")
        return jsonify({
            "user_message": user_input,
            "response": "–û–π, —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å! –ì–æ–±–ª–∏–Ω –≤ –∑–∞–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–µ...",
            "model": "error"
        }), 500

def clean_goblin_response(text):
    """–û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –≥–æ–±–ª–∏–Ω–∞ –æ—Ç –Ω–µ–Ω—É–∂–Ω—ã—Ö —á–∞—Å—Ç–µ–π"""
    import re
    # –£–¥–∞–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ —Å–∫–æ–±–∫–∞—Ö
    text = re.sub(r'\([^)]*\)', '', text)
    # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
    words = text.split()
    unique_words = []
    for word in words:
        if word not in unique_words[-3:]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–ª–æ–≤–∞
            unique_words.append(word)
    return ' '.join(unique_words).strip()

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)